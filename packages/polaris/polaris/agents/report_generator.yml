version: 1
id: report_generator
kind: agent_pipeline
description: Generate reports from Galaxy history analysis

start: fetch_histories

inputs:
  transcripts:
    type: transcript_stream
  context:
    type: object

state:
  histories:
    type: array
  selected_history:
    type: object
  contents:
    type: array
  dataset_details:
    type: array
  job_details:
    type: array
  citations:
    type: array
  workflow_analysis:
    type: string
  report:
    type: string

nodes:
  # Step 1: Fetch available histories
  fetch_histories:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.get
      input:
        limit: 20
    emit:
      state.histories: result
    next: select_history

  # Step 2: Use AI to select the appropriate history based on user request
  select_history:
    type: planner
    prompt: |
      You are helping a researcher generate a methods section for their publication.
      Select the history that best matches what the user wants to document.
      If the user mentioned a specific analysis or history name, select that one.
      Otherwise, select the most recently updated history with completed jobs.
    enum_from:
      state: histories
      field: name
    output_schema:
      type: object
      required: [history_name]
      properties:
        history_name:
          type: string
    emit:
      state.selected_history:
        name:
          $ref: result.history_name
    next: fetch_history_details

  # Step 3: Look up history ID and fetch history details
  fetch_history_details:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.show.get
      input:
        history_id:
          $expr:
            op: lookup
            from:
              $ref: state.histories
            match:
              field: name
              equals:
                $ref: state.selected_history.name
            select: id
    emit:
      state.selected_history: result
    next: fetch_contents

  # Step 4: Fetch the history contents to get dataset list
  fetch_contents:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.show.contents.get
      input:
        history_id:
          $ref: state.selected_history.id
        limit: 15
    emit:
      state.contents: result
    next: fetch_dataset_details

  # Step 5: Loop through datasets to get details including creating_job
  fetch_dataset_details:
    type: loop
    over:
      $ref: state.contents
    as: dataset
    delay: 0.1
    execute:
      op: api.call
      target: galaxy.datasets.show.get
      input:
        dataset_id:
          $ref: loop.dataset.id
    emit:
      state.dataset_details:
        $append:
          id:
            $ref: result.id
          name:
            $ref: result.name
          creating_job:
            $ref: result.creating_job
    next: fetch_job_details

  # Step 6: Loop through dataset details to fetch job info via creating_job
  fetch_job_details:
    type: loop
    over:
      $ref: state.dataset_details
    as: ds
    delay: 0.1
    execute:
      op: api.call
      target: galaxy.jobs.show.get
      input:
        job_id:
          $ref: loop.ds.creating_job
    emit:
      state.job_details:
        $append:
          tool_id:
            $ref: result.tool_id
          tool_version:
            $ref: result.tool_version
          state:
            $ref: result.state
          create_time:
            $ref: result.create_time
    next: fetch_citations

  # Step 7: Fetch citations for tools used in this history
  fetch_citations:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.show.citations.get
      input:
        history_id:
          $ref: state.selected_history.id
    emit:
      state.citations: result
    next: analyze_workflow

  # Step 8: Use AI to understand the analysis workflow
  analyze_workflow:
    type: reasoning
    prompt: |
      Analyze the jobs in this Galaxy history.

      IMPORTANT: Only describe tools that are ACTUALLY present in the job_details list.
      Do NOT make up or hallucinate tool names.

      Look at the "tool_id" field in each job to identify the actual tools used.
      Internal Galaxy tools start with "__" (like __DATA_FETCH__, __SET_METADATA__) - these are for data uploads, not analysis.

      Summarize:
      1. List the analysis tools that were run (exclude internal tools starting with "__")
      2. Describe the data processing workflow based on the tools used
      3. Note any tool versions if available
    input:
      history_name:
        $ref: state.selected_history.name
      job_details:
        $ref: state.job_details
    emit:
      state.workflow_analysis:
        $ref: result
    next: generate_methods

  # Step 9: Generate the report
  generate_methods:
    type: reasoning
    prompt: |
      Write a brief report summarizing this Galaxy history analysis.

      RULES:
      - Only mention tools from the workflow_analysis
      - Do NOT invent or hallucinate tool names
      - If workflow_analysis shows only internal tools (__DATA_FETCH__, etc.) with no analysis tools, say "This history contains uploaded data but no analysis has been performed yet."
      - If analysis tools were used, describe what they do in plain language

      Format as a short paragraph describing the analysis performed.
    input:
      history_name:
        $ref: state.selected_history.name
      workflow_analysis:
        $ref: state.workflow_analysis
      citations:
        $ref: state.citations
    emit:
      state.report:
        $ref: result
    next: done

  # Terminal node - return the generated report
  done:
    type: terminal
    output:
      selected_history:
        id:
          $ref: state.selected_history.id
        name:
          $ref: state.selected_history.name
      workflow_analysis:
        $ref: state.workflow_analysis
      report:
        $ref: state.report
