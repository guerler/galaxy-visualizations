version: 1
id: report_generator
kind: agent_pipeline
description: Generate reports from Galaxy history analysis

start: fetch_histories

inputs:
  transcripts:
    type: transcript_stream
  context:
    type: object

state:
  histories:
    type: array
  selected_history:
    type: object
  contents:
    type: array
  jobs:
    type: array
  citations:
    type: array
  workflow_analysis:
    type: string
  report:
    type: string

nodes:
  # Step 1: Fetch available histories
  fetch_histories:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.get
      input:
        limit: 20
    emit:
      state.histories: result
    next: select_history

  # Step 2: Use AI to select the appropriate history based on user request
  select_history:
    type: planner
    prompt: |
      You are helping a researcher generate a methods section for their publication.
      Select the history that best matches what the user wants to document.
      If the user mentioned a specific analysis or history name, select that one.
      Otherwise, select the most recently updated history with completed jobs.
    enum_from:
      state: histories
      field: name
    output_schema:
      type: object
      required: [history_name]
      properties:
        history_name:
          type: string
    emit:
      state.selected_history:
        name:
          $ref: result.history_name
    next: fetch_contents

  # Step 3: Fetch the history contents to get dataset information
  # Note: Limiting to 20 items to stay within LLM context limits
  fetch_contents:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.show.contents.get
      input:
        history_id:
          $expr:
            op: lookup
            from:
              $ref: state.histories
            match:
              field: name
              equals:
                $ref: state.selected_history.name
            select: id
        limit: 20
    emit:
      state.selected_history:
        id:
          $ref: run.input.history_id
      state.contents: result
    next: fetch_jobs

  # Step 4: Fetch jobs associated with this history
  # Note: Using job summaries for now - full details are too verbose for LLM context
  # TODO: Add $map expression to extract only relevant fields from job details
  fetch_jobs:
    type: executor
    run:
      op: api.call
      target: galaxy.jobs.get
      input:
        history_id:
          $ref: state.selected_history.id
        limit: 10
    emit:
      state.jobs: result
    next: fetch_citations

  # Step 5: Fetch citations for tools used in this history
  fetch_citations:
    type: executor
    run:
      op: api.call
      target: galaxy.histories.show.citations.get
      input:
        history_id:
          $ref: state.selected_history.id
    emit:
      state.citations: result
    next: analyze_workflow

  # Step 6: Use AI to understand the analysis workflow
  analyze_workflow:
    type: reasoning
    prompt: |
      Analyze the jobs and datasets in this Galaxy history.

      IMPORTANT: Only describe tools that are ACTUALLY present in the jobs list.
      Do NOT make up or hallucinate tool names. If only data upload jobs are present,
      say so clearly.

      Look at the "tool_id" field in each job to identify the actual tools used.
      Internal Galaxy tools start with "__" (like __DATA_FETCH__, __SET_METADATA__).

      Summarize:
      1. What tools were actually run (based on tool_id field)
      2. What types of files are in the history (based on contents)
      3. The apparent purpose of this history
    input:
      history_name:
        $ref: state.selected_history.name
      contents:
        $ref: state.contents
      jobs:
        $ref: state.jobs
    emit:
      state.workflow_analysis:
        $ref: result
    next: generate_methods

  # Step 7: Generate the report
  generate_methods:
    type: reasoning
    prompt: |
      Write a report summarizing this Galaxy history based on the analysis provided.

      CRITICAL RULES:
      - Only mention tools that were ACTUALLY used (from the workflow_analysis)
      - Do NOT invent or hallucinate tool names, versions, or citations
      - If no analysis tools were run (only data uploads), say "This history contains uploaded data files but no analysis jobs have been run yet."
      - Be honest about what was done vs what was not done

      If analysis tools were used:
      - Describe the workflow in logical order
      - Include actual tool names from the data
      - Include version numbers only if they appear in the data
    input:
      history_name:
        $ref: state.selected_history.name
      workflow_analysis:
        $ref: state.workflow_analysis
      citations:
        $ref: state.citations
    emit:
      state.report:
        $ref: result
    next: done

  # Terminal node - return the generated report
  done:
    type: terminal
    output:
      selected_history:
        id:
          $ref: state.selected_history.id
        name:
          $ref: state.selected_history.name
      workflow_analysis:
        $ref: state.workflow_analysis
      report:
        $ref: state.report
